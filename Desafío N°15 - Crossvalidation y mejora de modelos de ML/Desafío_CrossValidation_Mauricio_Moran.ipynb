{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafío entregable #13: CrossValidation y mejora de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, HalvingGridSearchCV, HalvingRandomSearchCV, RandomizedSearchCV, train_test_split\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este desafío se trabajará con el dataset \"California Housing\", el cual resumen información inmobiliaria de dicho estado de los EE.UU. Dicha información esta agrupada en \"block groups\" (BG), el cual es la unidad geográfica más pequeña que el U.S. Census Bureau registra informacion. Otra agrupación presente en el dataset es \"household\" (HH), que es el número de personas residentes en una casa. Un block group típicamente vive entre 600 y 3000 personas. Las variables presentes en el dataset son:\n",
    "\n",
    "- longitude: longitud del BG.\n",
    "- latitude: latitud del BG.\n",
    "- housing_median_age: mediana de la edad del BG.\n",
    "- total_rooms: promedio de ambientes por HH. \n",
    "- total_bedrooms: promedio de habitaciones por HH.\n",
    "- population: población del BG.\n",
    "- households: número de HH por BG. \n",
    "- median_income: mediana del ingreso del BG.\n",
    "- median_house_value: mediana del valor del HH.  \n",
    "- ocean_proximity: cercanía al océano, variable categórica.\n",
    "- gender: género mayoritario del BG.\n",
    "\n",
    "El objetivo es predecir la mediana del valor de los inmuebles, expresados en cientos de miles de dólares (US$ 100.000). Esta entrega hace foco en la validación cruzada y en el ajuste de hiperparámetros como mecanismo para la mejora de los modelos de aprendizaje autómatico.\n",
    "\n",
    "El procedimiento de limpieza, curado y estandarizacion/normalización de los datos es el mismo de la entrega anterior y no se los describirá en detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Housing_Price.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repaso del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20382 non-null  float64\n",
      " 3   total_rooms         20640 non-null  int64  \n",
      " 4   total_bedrooms      15758 non-null  float64\n",
      " 5   population          20596 non-null  float64\n",
      " 6   households          19335 non-null  object \n",
      " 7   median_income       17873 non-null  float64\n",
      " 8   median_house_value  20640 non-null  int64  \n",
      " 9   ocean_proximity     20640 non-null  object \n",
      " 10  gender              16620 non-null  object \n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>-119.569704</td>\n",
       "      <td>2.003532</td>\n",
       "      <td>-124.3500</td>\n",
       "      <td>-121.8000</td>\n",
       "      <td>-118.4900</td>\n",
       "      <td>-118.0100</td>\n",
       "      <td>-114.3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>32.5400</td>\n",
       "      <td>33.9300</td>\n",
       "      <td>34.2600</td>\n",
       "      <td>37.7100</td>\n",
       "      <td>41.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_median_age</th>\n",
       "      <td>20382.0</td>\n",
       "      <td>28.676283</td>\n",
       "      <td>12.589284</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.0000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bedrooms</th>\n",
       "      <td>15758.0</td>\n",
       "      <td>539.920104</td>\n",
       "      <td>419.834171</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>296.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>652.0000</td>\n",
       "      <td>6210.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20596.0</td>\n",
       "      <td>1424.928724</td>\n",
       "      <td>1132.237768</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.0000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_income</th>\n",
       "      <td>17873.0</td>\n",
       "      <td>3.939403</td>\n",
       "      <td>1.943517</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5986</td>\n",
       "      <td>3.5871</td>\n",
       "      <td>4.8304</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_house_value</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.0000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count           mean            std         min  \\\n",
       "longitude           20640.0    -119.569704       2.003532   -124.3500   \n",
       "latitude            20640.0      35.631861       2.135952     32.5400   \n",
       "housing_median_age  20382.0      28.676283      12.589284      1.0000   \n",
       "total_rooms         20640.0    2635.763081    2181.615252      2.0000   \n",
       "total_bedrooms      15758.0     539.920104     419.834171      1.0000   \n",
       "population          20596.0    1424.928724    1132.237768      3.0000   \n",
       "median_income       17873.0       3.939403       1.943517      0.4999   \n",
       "median_house_value  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                            25%          50%          75%          max  \n",
       "longitude             -121.8000    -118.4900    -118.0100    -114.3100  \n",
       "latitude                33.9300      34.2600      37.7100      41.9500  \n",
       "housing_median_age      18.0000      29.0000      37.0000      52.0000  \n",
       "total_rooms           1447.7500    2127.0000    3148.0000   39320.0000  \n",
       "total_bedrooms         296.0000     435.0000     652.0000    6210.0000  \n",
       "population             787.0000    1166.0000    1725.0000   35682.0000  \n",
       "median_income            2.5986       3.5871       4.8304      15.0001  \n",
       "median_house_value  119600.0000  179700.0000  264725.0000  500001.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>19335</td>\n",
       "      <td>1703</td>\n",
       "      <td>no</td>\n",
       "      <td>3080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocean_proximity</th>\n",
       "      <td>20640</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>16620</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>8673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count unique        top  freq\n",
       "households       19335   1703         no  3080\n",
       "ocean_proximity  20640      5  <1H OCEAN  9136\n",
       "gender           16620      2     female  8673"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = \"object\").T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['households'].replace(\"no\", np.nan , inplace=True)\n",
    "df['households'] = df['households'].astype('float64')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de datos tipo NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['gender'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord = preprocessing.OrdinalEncoder()\n",
    "df['ocean_proximity'] = ord.fit_transform(df[['ocean_proximity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors = 5, weights = \"uniform\")\n",
    "df2 = pd.DataFrame(imputer.fit_transform(df), columns = df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_shapefile_path = \"ne_110m_coastline/ne_110m_coastline.shp\"\n",
    "coastal_data = gpd.read_file(coastal_shapefile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mauri\\AppData\\Local\\Temp\\ipykernel_6636\\1402484739.py:8: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  distances = coastal_data.distance(point) # Calculamos la distancia a todos los puntos de la costa\n"
     ]
    }
   ],
   "source": [
    "df2['distance_coast'] = None\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    latitude = row['latitude']\n",
    "    longitude = row['longitude']\n",
    "    \n",
    "    point = Point(longitude, latitude)\n",
    "    distances = coastal_data.distance(point) # Calculamos la distancia a todos los puntos de la costa\n",
    "    distances_min = distances.min() # Encontramos el mínimo valor de distancia\n",
    "\n",
    "    df2.at[index, 'distance_coast'] = distances_min * 111.0445 \n",
    "    \n",
    "df2['distance_coast'] = df2['distance_coast'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "los_angeles = [34.1141, -118.4068] # Longitud y latitud\n",
    "san_diego = [32.8313, -117.1222]\n",
    "san_jose = [37.3012, -121.848]\n",
    "san_francisco = [37.7558, -122.4449]\n",
    "fresno = [36.783, -119.7939]\n",
    "\n",
    "cities = [los_angeles, san_diego, san_jose, san_francisco, fresno]\n",
    "names = ['los_angeles', 'san_diego', 'san_jose', 'san_francisco', 'fresno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cities)):\n",
    "    \n",
    "    df2[f'distance_{names[i]}'] = None\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        latitude = row['latitude']\n",
    "        longitude = row['longitude']\n",
    "        \n",
    "        point1 = Point(cities[i][1], cities[i][0])\n",
    "        point2 = Point(longitude, latitude)\n",
    "        \n",
    "        distance = point1.distance(point2)\n",
    "        \n",
    "        df2.at[index, f'distance_{names[i]}'] = distance * 111.0445 \n",
    "        \n",
    "    df2[f'distance_{names[i]}'] = df2[f'distance_{names[i]}'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(['ocean_proximity', 'latitude', 'longitude'], axis = 1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducción de dimensionalidad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reducirá el número de variables a través del método de importancia, empleando bosques de decisión. Este método probó ser el más rápido y por ello se lo selecciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer()\n",
    "\n",
    "df3 = df2.copy()\n",
    "df4 = pd.DataFrame(pt.fit_transform(df3), columns = df3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df4.drop(['median_house_value'], axis = 1) \n",
    "y = df4['median_house_value']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "regr = RandomForestRegressor(max_depth = 3, random_state = 0)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "impor_variable = regr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>distance_coast</td>\n",
       "      <td>0.521505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>median_income</td>\n",
       "      <td>0.474019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>distance_fresno</td>\n",
       "      <td>0.004362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>distance_san_francisco</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housing_median_age</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_rooms</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_bedrooms</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>population</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>households</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>distance_los_angeles</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>distance_san_diego</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>distance_san_jose</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "6           distance_coast    0.521505\n",
       "5            median_income    0.474019\n",
       "11         distance_fresno    0.004362\n",
       "10  distance_san_francisco    0.000114\n",
       "0       housing_median_age    0.000000\n",
       "1              total_rooms    0.000000\n",
       "2           total_bedrooms    0.000000\n",
       "3               population    0.000000\n",
       "4               households    0.000000\n",
       "7     distance_los_angeles    0.000000\n",
       "8       distance_san_diego    0.000000\n",
       "9        distance_san_jose    0.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importancias = pd.DataFrame({'feature': list(X.columns), 'importance': impor_variable}).sort_values('importance', ascending = False)\n",
    "importancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'distance_los_angeles',\n",
       " 'distance_san_diego',\n",
       " 'distance_san_jose']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impor_nulas = list(importancias[importancias['importance'] == 0.0]['feature'])\n",
    "impor_nulas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas son las variables que descartaremos, dado que no parecen contribuir a la predición de la mediana del valor de los inmuebles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_income</th>\n",
       "      <th>distance_coast</th>\n",
       "      <th>distance_san_francisco</th>\n",
       "      <th>distance_fresno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.926231</td>\n",
       "      <td>-0.098137</td>\n",
       "      <td>-1.602920</td>\n",
       "      <td>-0.314668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.920074</td>\n",
       "      <td>-0.087038</td>\n",
       "      <td>-1.603219</td>\n",
       "      <td>-0.331393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.628791</td>\n",
       "      <td>-0.152815</td>\n",
       "      <td>-1.623067</td>\n",
       "      <td>-0.317584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.073383</td>\n",
       "      <td>-0.183544</td>\n",
       "      <td>-1.631276</td>\n",
       "      <td>-0.308713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.211877</td>\n",
       "      <td>-0.183544</td>\n",
       "      <td>-1.631276</td>\n",
       "      <td>-0.308713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   median_income  distance_coast  distance_san_francisco  distance_fresno\n",
       "0       1.926231       -0.098137               -1.602920        -0.314668\n",
       "1       1.920074       -0.087038               -1.603219        -0.331393\n",
       "2       1.628791       -0.152815               -1.623067        -0.317584\n",
       "3       1.073383       -0.183544               -1.631276        -0.308713\n",
       "4       0.211877       -0.183544               -1.631276        -0.308713"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.drop(columns = impor_nulas)\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este el dataset resultante, con las variables que tienen importancia distinta de cero y que serán utilizadas en la terna entrenamiento - validación - testeo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejora de modelos de aprendizaje automático"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dice el título de la sección, se buscarán mejorar los modelos mediante validación cruzada y por medio del ajuste fino de los hiperparámetros mediante el uso de diversos algoritmos. El primero que veremos es la validación cruzada, puedo que luego el ajuste fino de los hiperparámetros hace uso extensivo de la misma."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se empleará el algoritmo de validación cruzada KFold, en donde se particiona el trainset en k partes, quedando una de ellas como validación y las restantes de entrenamiento. Este algoritmo puede ser potencialmente muy lento, es por ello que se buscará una alternativa más rápida a XGBoost, que fue el algoritmo que mejor se desempeñó en entregas pasadas. Dicha alternativa es el algoritmo LightGBM, que también es un modelo de Boosting, pero que se caracteriza por su velocidad de cómputo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las métricas obtenidas para XGBoost son:\n",
      "      MAE = 0.2832\n",
      "      MSE = 0.1642\n",
      "      R2 = 0.837\n",
      "      Tiempo = 1.0014 s\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "start_time = time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "tiempo = execution_time\n",
    "\n",
    "print(f'''Las métricas obtenidas para XGBoost son:\n",
    "      MAE = {MAE.round(4)}\n",
    "      MSE = {MSE.round(4)}\n",
    "      R2 = {r2.round(4)}\n",
    "      Tiempo = {np.round(tiempo,4)} s''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las métricas obtenidas para LightGMB son:\n",
      "      MAE = 0.2878\n",
      "      MSE = 0.1639\n",
      "      R2 = 0.8373\n",
      "      Tiempo = 0.1659 s\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred = lgbm.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "tiempo = execution_time\n",
    "\n",
    "print(f'''Las métricas obtenidas para LightGMB son:\n",
    "      MAE = {MAE.round(4)}\n",
    "      MSE = {MSE.round(4)}\n",
    "      R2 = {r2.round(4)}\n",
    "      Tiempo = {np.round(tiempo,4)} s''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que ambos algortimos poseen métricas de bondad de ajuste muy similares, sin embargo, XGBoost tarda aprox. 1 s, en tanto que con LightGMB este tiempo es de sólo 0.2 s, sólo una quinta parte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de cada fold = [0.8404 0.8298 0.8509 0.8362 0.8388 0.8308 0.8502 0.8481 0.8281 0.8337]\n",
      "R2 promedio = 0.8387\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "model = LGBMRegressor()\n",
    "score = cross_val_score(model, X, y, cv = kf, scoring = 'r2')\n",
    "\n",
    "print(f'R2 de cada fold = {score.round(4)}')\n",
    "print(f'R2 promedio = {\"{:.4f}\".format(score.mean())}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al particionar el trainset en k = 10 folds y luego aplicar el modelo a cada uno de estos fold se obtiene luego la métrica R2 promedio. Este valor es muy cercano al obtenido en la aplicación del modelo en el trainset al completo. Esto indica que el modelo aplicado (con todos los hiperparámetros en valores por defecto) hace un buen ajuste."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste manual"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El trabajo de ajuste fino de los parámetros puede hacerse de forma manual a través del mismo algoritmo cross_val_score. Inspeccionaremos diversos hiperparámetros y vamos eligiendo secuencialmente el que mejor valor de R2 ofrece, así hasta llegar al modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 promedio tipo de boosting: gbdt = 0.8387\n",
      "R2 promedio tipo de boosting: dart = 0.8053\n"
     ]
    }
   ],
   "source": [
    "boosting_type = ['gbdt', 'dart']\n",
    "\n",
    "for boosting in boosting_type:\n",
    "    model = LGBMRegressor(boosting_type = boosting)\n",
    "    score = cross_val_score(model, X, y, cv = kf, scoring = 'r2')\n",
    "    print(f'R2 promedio tipo de boosting: {boosting} = {\"{:.4f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 promedio profundidad máxima: 1 = 0.7274\n",
      "R2 promedio profundidad máxima: 2 = 0.7677\n",
      "R2 promedio profundidad máxima: 3 = 0.7910\n",
      "R2 promedio profundidad máxima: 4 = 0.8094\n",
      "R2 promedio profundidad máxima: 5 = 0.8243\n",
      "R2 promedio profundidad máxima: -1 = 0.8387\n"
     ]
    }
   ],
   "source": [
    "max_depth = [1, 2, 3, 4, 5, -1]\n",
    "\n",
    "for depth in max_depth:\n",
    "    model = LGBMRegressor(boosting_type = 'gbdt', max_depth = depth)\n",
    "    score = cross_val_score(model, X, y, cv = kf, scoring = 'r2')\n",
    "    print(f'R2 promedio profundidad máxima: {depth} = {\"{:.4f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 promedio tasa de aprendizaje: 0.001 = 0.1331\n",
      "R2 promedio tasa de aprendizaje: 0.01 = 0.6581\n",
      "R2 promedio tasa de aprendizaje: 0.1 = 0.8387\n",
      "R2 promedio tasa de aprendizaje: 1 = 0.8147\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "for rate in learning_rate:\n",
    "    model = LGBMRegressor(boosting_type = 'gbdt', max_depth = -1, learning_rate = rate)\n",
    "    score = cross_val_score(model, X, y, cv = kf, scoring = 'r2')\n",
    "    print(f'R2 promedio tasa de aprendizaje: {rate} = {\"{:.4f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 promedio número de estimadores: 10 = 0.6677\n",
      "R2 promedio número de estimadores: 50 = 0.8229\n",
      "R2 promedio número de estimadores: 100 = 0.8387\n",
      "R2 promedio número de estimadores: 500 = 0.8559\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 50, 100, 500]\n",
    "\n",
    "for n in n_estimators:\n",
    "    model = LGBMRegressor(boosting_type = 'gbdt', max_depth = -1, learning_rate = 0.1, n_estimators = n)\n",
    "    score = cross_val_score(model, X, y, cv = kf, scoring = 'r2')\n",
    "    print(f'R2 promedio número de estimadores: {n} = {\"{:.4f}\".format(score.mean())}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de ajustar diversos hiperparámetros, seleccionamos los siguientes como definitivos boosting_type = 'gbdt', max_depth = -1, learning_rate = 0.1, n_estimators = 500 y hacemos una prueba rápida de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(y, y_pred):\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    return mae, mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.9185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.2680</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.8518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset     MAE     MSE      R2\n",
       "0   Train  0.2051  0.0813  0.9185\n",
       "1    Test  0.2680  0.1492  0.8518"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor(boosting_type = 'gbdt', max_depth = -1, learning_rate = 0.1, n_estimators = 500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mae_train, mse_train, r2_train = metricas(y_train, y_pred_train)\n",
    "mae_test, mse_test, r2_test = metricas(y_test, y_pred_test)\n",
    "\n",
    "comparacion = pd.DataFrame({'Dataset': ['Train', 'Test'], \n",
    "                            'MAE': [mae_train, mae_test], \n",
    "                            'MSE': [mse_train, mse_test], \n",
    "                            'R2': [r2_train, r2_test]})\n",
    "comparacion.round(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con una prueba rápida observamos que las métricas en el testset son consistentemente menores que en el trainset, indicando que el modelo no está haciendo overfitting.\n",
    "\n",
    "Existen métodos automáticos para realizar esta exploración de hiperparámetros, probaremos varios de ellos y realizaremos una comparación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search automatiza la busqueda de los hiperparámetros, haciendo una grilla de todas las combinaciones posibles de los hiperparámetros solicitados, que se introducen en el algoritmo GridSearchCV como un diccionario. GridSearchCV luego selecciona el conjunto de hiperparámetros que mejores métricas ofrece. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores Parametros {'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 500}\n",
      "Mejor CV score 0.8492220791164536\n",
      "R2 del modelo = 0.8518\n"
     ]
    }
   ],
   "source": [
    "params_grid = {\n",
    "        'boosting_type': ['gbdt', 'dart'],\n",
    "        'max_depth': [1, 2, 3, 4, 5, -1],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "        'n_estimators': [10, 50, 100, 500],\n",
    "        }\n",
    "\n",
    "model = LGBMRegressor()\n",
    "start_time = time.time()\n",
    "\n",
    "grid_cv = GridSearchCV(model, params_grid, scoring = 'r2', n_jobs=-1, cv = 5)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "time_grid_cv = end_time - start_time\n",
    "\n",
    "print(\"Mejores Parametros\", grid_cv.best_params_)\n",
    "print(\"Mejor CV score\", grid_cv.best_score_)\n",
    "print(f'R2 del modelo = {round(r2_score(y_test, grid_cv.predict(X_test)), 4)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta búsqueda automática arribamos a los hiperparámetros que más alto valor de R2, que son los mismos que se encontraron por medio de la búsqueda manual."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search CV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo prueba un número fijo de combinaciones de hiperparámetros (n_iter = 10) al azar, es decir, no prueba todas las posibles combinaciones pero igualmente informa la que mejor resultados da."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parametros {'n_estimators': 500, 'max_depth': -1, 'learning_rate': 0.1, 'boosting_type': 'gbdt'}\n",
      "Mejor score de CV 0.8492220791164536\n",
      "Accuracy del modelo = 0.8518\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rgrid_cv = RandomizedSearchCV(model, params_grid, scoring = 'r2', n_jobs=-1, cv = 5)\n",
    "rgrid_cv.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "time_rgrid_cv = end_time - start_time\n",
    "\n",
    "print(\"Mejores parametros\", rgrid_cv.best_params_)\n",
    "print(\"Mejor score de CV\", rgrid_cv.best_score_)\n",
    "print(f'Accuracy del modelo = {round(r2_score(y_test, rgrid_cv.predict(X_test)), 4)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halving Grid Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Halving Grid Search opera por división sucesiva por mitades. Es un proceso de selección iterativo en el que todas las combinaciones de parámetros se evalúan con una pequeña cantidad de recursos en la primera iteración. Sólo algunos de estas combinaciones se seleccionan para la siguiente iteración, a la que se asignarán más recursos. Para el ajuste de parámetros, el recurso suele ser el número de muestras de entrenamiento, pero pueden ser otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parametros {'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 100}\n",
      "Mejor Score CV 0.8363497204447796\n",
      "Accuracy del modelo = 0.8373\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "halving_cv = HalvingGridSearchCV(model, params_grid, scoring = 'r2', n_jobs=-1, factor = 3, cv = 5)\n",
    "halving_cv.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "time_halving_cv = end_time - start_time\n",
    "\n",
    "print(\"Mejores parametros\", halving_cv.best_params_)\n",
    "print(\"Mejor Score CV\", halving_cv.best_score_)\n",
    "print(f'Accuracy del modelo = {round(r2_score(y_test, halving_cv.predict(X_test)), 4)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halving Randomized Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Halving Randomized Search opera similar que su similar \"no aleatorio\" sin embargo sólo algunas combinaciones de hiperparámetros son seleccionadas al azar,  y éste es el punto de partida en el que el proceso iterativo comienza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programas\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 192 is smaller than n_iter=1548. Running 192 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parametros {'n_estimators': 500, 'max_depth': -1, 'learning_rate': 0.01, 'boosting_type': 'gbdt'}\n",
      "Mejor CV score 0.7888642540342572\n",
      "Accuracy del modelo = 0.8229\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rhalving_cv = HalvingRandomSearchCV(model, params_grid, scoring = 'r2', n_jobs=-1, factor = 3, cv = 5)\n",
    "rhalving_cv.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "time_rhalving_cv = end_time - start_time\n",
    "\n",
    "print(\"Mejores parametros\", rhalving_cv.best_params_)\n",
    "print(\"Mejor CV score\", rhalving_cv.best_score_)\n",
    "print(f'Accuracy del modelo = {round(r2_score(y_test, rhalving_cv.predict(X_test)), 4)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de métodos de búsqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algoritmo</th>\n",
       "      <th>Max. R2</th>\n",
       "      <th>Tiempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid Search</td>\n",
       "      <td>0.8492</td>\n",
       "      <td>172.7762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Randomized Grid Search</td>\n",
       "      <td>0.8492</td>\n",
       "      <td>6.8767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Halving Grid Search</td>\n",
       "      <td>0.8363</td>\n",
       "      <td>43.4511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Randomized Halving Grid Search</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>5.7125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Algoritmo  Max. R2    Tiempo\n",
       "0                     Grid Search   0.8492  172.7762\n",
       "1          Randomized Grid Search   0.8492    6.8767\n",
       "2             Halving Grid Search   0.8363   43.4511\n",
       "3  Randomized Halving Grid Search   0.7889    5.7125"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper = pd.DataFrame({'Algoritmo': ['Grid Search','Randomized Grid Search','Halving Grid Search','Randomized Halving Grid Search'], \n",
    "                            'Max. R2': [grid_cv.best_score_, rgrid_cv.best_score_, halving_cv.best_score_, rhalving_cv.best_score_], \n",
    "                            'Tiempo': [time_grid_cv, time_rgrid_cv, time_halving_cv, time_rhalving_cv]\n",
    "                            })\n",
    "hyper.round(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando los diversos métodos, encontramos que todos los métodos excepto Randomized Halving Grid Search obtuvieron métricas similares, ésta última ofreció valores bajos. Es importante considerar el tiempo de cómputo, Grid Search es el que más demora, al analizar todas las posibles combinaciones. Por otro lado Halving Grid Search disminuye este tiempo considerablemente. Por último Randomized Grid Search y Randomized Halving Grid Search tardaron menos de diez segundos, demostrando ser súmamente rápidos. Hay que recalcar que la naturaleza random de los métodos random hace que ofrezcan resultados diferentes y tarden tiempos distintos cada vez que se los ejecuta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
